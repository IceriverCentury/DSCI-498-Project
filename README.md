# DSCI-498-Project

# Project Title: Abusive Language Detection From Joined Modelling

# Project Abstract
## Effectively detecting aggressive and abusive language is crucial for maintaining a healthy online environment on social media platforms. While the NLP community has made significant progress in abuse detection through various methods, existing approaches primarily focus on independent aspects, such as linguistic features of comments or user community behavior. However, they often overlook the intrinsic connection between language and emotional state. Building on the foundation of the Joint Modelling of Emotion and Abusive Language Detection paper, this project seeks to enhance abusive language detection by leveraging a joint modeling approach. Specifically, it aims to explore a multi-task learning framework, where different tasks inform each other, to assess whether incorporating affective features improves detection performance.

## This study will expand on previous work in two key ways. First, it will incorporate at least one additional recent dataset to ensure a broader evaluation across different contexts. Second, it will introduce an additional auxiliary task beyond emotion detection to further refine the modelâ€™s ability to distinguish abusive language. By integrating multiple related tasks, this approach aims to provide deeper insights into the interplay between emotional expression and abusive content, ultimately leading to more robust and context-aware abuse detection models.


# Datasets 
## Abuse Detection
### OffensEval 2019 (OffenseEval) - https://huggingface.co/datasets/christophsonntag/OLID
### Waseem and Hovy 2016 (Waseem&Hovy) - https://github.com/zeeraktalat/hatespeech/tree/master
## Emotion Detection
### SemEval 2018 (SemEval18) - https://competitions.codalab.org/competitions/17751#learn_the_details-datasets








